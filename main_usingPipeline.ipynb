{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:30:45.651371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization, Input, LeakyReLU\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] Logical GPUs: [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 09:58:20.424445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 09:58:20.821050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4646 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU and enable memory growth\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        # print(len(gpus), \"Physical GPUs:\", len(logical_gpus), \"Logical GPU\")\n",
    "        print(f'Physical GPUs: {gpus} Logical GPUs: {logical_gpus}')\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print('Error: ', e)\n",
    "else:\n",
    "    print('No GPUs found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'>\n"
     ]
    }
   ],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "# sess = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated time: 1.5 min\n",
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/coding-drive/DATASETS/face-recognition-tensorflow/', \n",
    "    batch_size=4,\n",
    "    image_size=(224, 224),\n",
    "    color_mode='grayscale',\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/coding-drive/DATASETS/face-recognition-tensorflow-test-data/',\n",
    "    batch_size=4,\n",
    "    image_size=(224, 224),\n",
    "    color_mode='grayscale',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION OF THE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iter = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = data_iter.next()\n",
    "# for i in range(4):\n",
    "#     plt.subplot(2, 2, i+1)\n",
    "#     plt.imshow(batch[0][i].reshape(224, 224), cmap='gray')\n",
    "#     plt.title(batch[1][i])\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.map(lambda x,y: (x/255, y))\n",
    "test = test.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(len(data)*.9)\n",
    "# val_size = int(len(data)*.2)\n",
    "# test_size = int(len(data)*.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = data.take(train_size)\n",
    "# test = data.skip(train_size).take(test_size)\n",
    "# test = data.skip(train_size+val_size).take(test_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:30:58.689290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 16:30:59.692782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4646 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"attention_1\" (type SeqSelfAttention).\n\nin user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras_self_attention/seq_self_attention.py\", line 158, in call  *\n        e = self._call_additive_emission(inputs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras_self_attention/seq_self_attention.py\", line 195, in _call_additive_emission  *\n        q = K.expand_dims(K.dot(inputs, self.Wt), 2)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 2450, in dot\n        tf.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:]\n\n    ValueError: Dimensions must be equal, but are 32 and 224 for '{{node attention_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](attention_1/Reshape, attention_1/Reshape_1)' with input shapes: [?,32], [224,32].\n\n\nCall arguments received by layer \"attention_1\" (type SeqSelfAttention):\n  • inputs=tf.Tensor(shape=(None, 224, 224, 32), dtype=float32)\n  • mask=None\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39madd(LeakyReLU(alpha\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleaky_relu_2\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39madd(BatchNormalization(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbatch_norm_2\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m model\u001b[39m.\u001b[39;49madd(SeqSelfAttention(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mattention_1\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39madd(MaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)))\n\u001b[1;32m     16\u001b[0m \u001b[39m# Convolutional layer - 2 (64 filters, 3x3 kernel, relu activation)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file6i_oya0z.py:43\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, mask, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mattention_type \u001b[39m==\u001b[39m ag__\u001b[39m.\u001b[39mld(SeqSelfAttention)\u001b[39m.\u001b[39mATTENTION_TYPE_MUL, if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m e \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mattention_type \u001b[39m==\u001b[39;49m ag__\u001b[39m.\u001b[39;49mld(SeqSelfAttention)\u001b[39m.\u001b[39;49mATTENTION_TYPE_ADD, if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[39m'\u001b[39;49m\u001b[39me\u001b[39;49m\u001b[39m'\u001b[39;49m,), \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_2\u001b[39m():\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m (e,)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file6i_oya0z.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mif_body_1\u001b[39m():\n\u001b[1;32m     20\u001b[0m     \u001b[39mnonlocal\u001b[39;00m e\n\u001b[0;32m---> 21\u001b[0m     e \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_call_additive_emission, (ag__\u001b[39m.\u001b[39;49mld(inputs),), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefs7o7xtb.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___call_additive_emission\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m input_shape \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(inputs),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m (batch_size, input_len) \u001b[39m=\u001b[39m (ag__\u001b[39m.\u001b[39mld(input_shape)[\u001b[39m0\u001b[39m], ag__\u001b[39m.\u001b[39mld(input_shape)[\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m q \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49mdot, (ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mWt), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39m2\u001b[39m), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m k \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39mdot, (ag__\u001b[39m.\u001b[39mld(inputs), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mWx), \u001b[39mNone\u001b[39;00m, fscope), \u001b[39m1\u001b[39m), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"attention_1\" (type SeqSelfAttention).\n\nin user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras_self_attention/seq_self_attention.py\", line 158, in call  *\n        e = self._call_additive_emission(inputs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras_self_attention/seq_self_attention.py\", line 195, in _call_additive_emission  *\n        q = K.expand_dims(K.dot(inputs, self.Wt), 2)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 2450, in dot\n        tf.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:]\n\n    ValueError: Dimensions must be equal, but are 32 and 224 for '{{node attention_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](attention_1/Reshape, attention_1/Reshape_1)' with input shapes: [?,32], [224,32].\n\n\nCall arguments received by layer \"attention_1\" (type SeqSelfAttention):\n  • inputs=tf.Tensor(shape=(None, 224, 224, 32), dtype=float32)\n  • mask=None\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(224, 224, 1), name='input'))\n",
    "\n",
    "# Convolutional layer - 1 (32 filters, 3x3 kernel, relu activation)\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', name='conv2d_1'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_1'))\n",
    "model.add(BatchNormalization(name='batch_norm_1'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', name='conv2d_2'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_2'))\n",
    "model.add(BatchNormalization(name='batch_norm_2'))\n",
    "\n",
    "model.add(SeqSelfAttention(name='attention_1'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer - 2 (64 filters, 3x3 kernel, relu activation)\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv2d_3'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_3'))\n",
    "model.add(BatchNormalization(name='batch_norm_3'))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3),padding='same', name='conv2d_4'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_4'))\n",
    "model.add(BatchNormalization(name='batch_norm_4'))\n",
    "\n",
    "model.add(SeqSelfAttention(name='attention_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer - 3 (128 filters, 3x3 kernel, relu activation)\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', name='conv2d_5'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_5'))\n",
    "model.add(BatchNormalization(name='batch_norm_5'))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', name='conv2d_6'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_6'))\n",
    "model.add(BatchNormalization(name='batch_norm_6'))\n",
    "\n",
    "model.add(SeqSelfAttention(name='attention_3'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer - 4 (256 filters, 3x3 kernel, relu activation)\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='same', name='conv2d_7'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_7'))\n",
    "model.add(BatchNormalization(name='batch_norm_7'))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='same', name='conv2d_8'))\n",
    "model.add(LeakyReLU(alpha=0.1, name='leaky_relu_8'))\n",
    "model.add(BatchNormalization(name='batch_norm_8'))\n",
    "\n",
    "model.add(SeqSelfAttention(name='attention_4'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layer - 1 (512 neurons, relu activation)\n",
    "model.add(Dense(512, activation='relu', name='dense_1'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu', name='dense_2'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense layer - 2 (128 neurons, relu activation)\n",
    "model.add(Dense(128, activation='relu', name='dense_3'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense layer - output (3 neurons, softmax activation)\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input('Enter model name: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train, \n",
    "    epochs=10, \n",
    "    validation_data=test, \n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=f\"training_output/{model_name}/tensorboard/fit/\" + datetime.datetime.now().strftime(\"%m-%d_%H-%M-%S\"),\n",
    "            histogram_freq=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f'training_output/{model_name}/checkpoints/'+'epoch_{epoch: 02d}_val_loss_{val_loss: .2f}.hdf5',\n",
    "            save_freq='epoch',\n",
    "            save_best_only=False,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau('val_loss', patience=2, verbose=1),\n",
    "        tf.keras.callbacks.CSVLogger(f'training_output/{model_name}/training_log.csv'),\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10**(epoch / 20)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'training_output/{model_name}/final_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'],\n",
    "         color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'],\n",
    "         color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = Precision()\n",
    "# re = Recall()\n",
    "# acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = test_iter.next()\n",
    "# for i in range(4):\n",
    "#     plt.subplot(2, 2, i+1)\n",
    "#     plt.imshow(batch[0][i].reshape(224, 224, 1), cmap='gray')\n",
    "#     plt.title(batch[1][i])\n",
    "#     plt.axis('off')\n",
    "#     print(\n",
    "#         f'Predicted: {model.predict(batch[0][i].reshape(1, 224, 224, 1))[0].argmax()} Actual: {batch[1][i]}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in test.as_numpy_iterator(): \n",
    "#     img_batch, label_batch = batch\n",
    "#     yhat = model.predict(img_batch)\n",
    "#     pre.update_state(label_batch, yhat)\n",
    "#     re.update_state(label_batch, yhat)\n",
    "#     acc.update_state(label_batch, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pre.result(), re.result(), acc.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
